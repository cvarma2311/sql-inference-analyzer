"""
CORRECTED SQL GENERATOR
Fixed model fallback, schema detection, sanity checks, and cache handling
"""

import logging
import re
import json
import time
from training_data import TRAINING_QA_PAIRS, SQL_RULES, get_comprehensive_query_for_training
import ollama
from sqlalchemy import text
from typing import Optional, Dict, List, Tuple
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')

class AdaptiveLLMGenerator:
    """Multi-model SQL generator with proper fallback logic"""
    
    def __init__(self, rag_system, validator, training_data_module, max_retries=3, models=None):
        self.rag_system = rag_system
        self.validator = validator
        self.training_data_module = training_data_module
        self.max_retries = max_retries
        
        if models is None:
            self.models = ["llama3.1:8b", "deepseek-coder-v2"]
        else:
            self.models = models if isinstance(models, list) else [models]
        
        self.current_model = self.models[0]
        
        self.model_stats = {model: {
            'attempts': 0,
            'successes': 0,
            'failures': 0,
            'avg_time': 0,
            'total_time': 0
        } for model in self.models}

    def generate(self, question: str, use_few_shot: bool = True, 
                force_error: str = "", last_sql: str = "", 
                model_name: Optional[str] = None) -> Tuple[str, bool, str]:
        """
         CORRECTED: Generate SQL with proper model fallback
        Tries requested model first, then falls back to other models
        """
        start_time = time.time()
        
        #  FIX: Proper model prioritization
        if model_name and model_name in self.models:
            # Try requested model first, then others as fallback
            models_to_try = [model_name] + [m for m in self.models if m != model_name]
        else:
            models_to_try = self.models
        
        logging.info(f"  Model priority: {models_to_try}")
        
        for model in models_to_try:
            self.current_model = model
            logging.info(f"\n--- Attempting with model: {self.current_model} ---")
            
            last_error = force_error
            generated_sql = ""
            
            for attempt in range(self.max_retries):
                logging.info(f"  Attempt #{attempt + 1}/{self.max_retries}")
                
                self.model_stats[self.current_model]['attempts'] += 1
                
                prompt = self._build_adaptive_prompt(
                    question, generated_sql, last_error, 
                    attempt, use_few_shot
                )
                
                try:
                    options = {
                        "num_predict": 4096,
                        "num_ctx": 8192,
                        "temperature": 0.1
                    }
                    response = ollama.generate(model=self.current_model, prompt=prompt, options=options)
                    generated_sql = self._clean_sql(response['response'])
                    
                    is_valid, error = self.validator.validate_sql(generated_sql)
                    if is_valid:
                        elapsed = time.time() - start_time
                        self.model_stats[self.current_model]['successes'] += 1
                        self.model_stats[self.current_model]['total_time'] += elapsed
                        self.model_stats[self.current_model]['avg_time'] = (
                            self.model_stats[self.current_model]['total_time'] / 
                            self.model_stats[self.current_model]['successes']
                        )
                        logging.info(f"   Valid SQL generated by {self.current_model} ({elapsed:.2f}s)")
                        return generated_sql, True, self.current_model
                    else:
                        logging.warning(f"  ✗ Validation failed: {error}")
                        last_error = error
                
                except Exception as e:
                    logging.error(f"  ✗ Generation error: {e}")
                    last_error = str(e)
            
            # All retries failed for this model
            self.model_stats[self.current_model]['failures'] += 1
            logging.warning(f"  ✗ All retries failed for {self.current_model}")
        
        # All models failed
        logging.error("  ✗ All models exhausted")
        return generated_sql or "SELECT 'Generation failed' AS error;", False, self.current_model

    def _build_adaptive_prompt(self, question: str, last_sql: str, 
                               last_error: str, attempt: int, use_few_shot: bool) -> str:
        """Build adaptive prompt with context"""
        normalized_question = self.rag_system.normalize_question(question)
        
        # Get context from RAG
        context_examples = self.rag_system.retrieve_relevant_context(
            question, 
            top_k=3 if use_few_shot else 5
        )
        
        #  FIX: Improved table detection from multiple sources
        retrieved_tables = set()
        
        # 1. From Schema Metadata
        for doc in context_examples:
            metadata = doc.get('metadata', {})  
            if metadata.get('type') == 'schema':
                table_name = metadata.get('table')
                if table_name:
                    retrieved_tables.add(table_name)
        
        # 2. From QA Examples (simple keyword match from valid tables)
        valid_tables = getattr(self.training_data_module, 'SQL_RULES', {}).get('valid_tables', [])
        for doc in context_examples:
            if doc.get('metadata', {}).get('type') == 'example':
                text_content = doc.get('text', '').lower()
                for tbl in valid_tables:
                    if tbl in text_content:
                        retrieved_tables.add(tbl)

        # 3. From Concept Mapping (Question Analysis)
        concept_map = getattr(self.training_data_module, 'SQL_RULES', {}).get('concept_to_table_map', {})
        q_lower = normalized_question.lower()
        for concept, table in concept_map.items():
            if concept in q_lower:
                retrieved_tables.add(table)
        
        relevant_tables = list(retrieved_tables) or ['vts_alert_history', 'vts_truck_master']
        schema_info = self._get_focused_schema(relevant_tables)
        examples_info = "\n\n".join([ex['text'] for ex in context_examples])
        
        # Get dynamic rules from training data
        sql_rules = getattr(self.training_data_module, 'SQL_RULES', {})
        business_rules = sql_rules.get('business_rules', '')
        general_rules = sql_rules.get('general_rules', '')

        prompt = f"""You are a PostgreSQL expert for a Vehicle Tracking System.

**CRITICAL RULES:**
1. Use ONLY columns from the provided schema.
2. Return ONLY SQL - no explanations.
{general_rules}

**BUSINESS LOGIC:**
{business_rules}

**SCHEMA:**
{schema_info}

**EXAMPLES:**
{examples_info}
"""
        
        if attempt > 0:
            prompt += f"""
**PREVIOUS ATTEMPT FAILED:**
SQL: {last_sql}
Error: {last_error}

Fix the error and return ONLY the corrected SQL.
"""
        else:
            prompt += f"""
**USER QUESTION:** {normalized_question}

**YOUR SQL:**
"""
        
        return prompt

    def _clean_sql(self, sql: str) -> str:
        """Clean SQL output"""
        # Remove markdown
        sql = re.sub(r'```sql\n?', '', sql, flags=re.IGNORECASE)
        sql = re.sub(r'```', '', sql)
        
        # Find SQL start
        select_pos = sql.upper().find("SELECT ")
        with_pos = sql.upper().find("WITH ")
        
        start_pos = -1
        if with_pos != -1 and (with_pos < select_pos or select_pos == -1):
            start_pos = with_pos
        elif select_pos != -1:
            start_pos = select_pos
        
        if start_pos != -1:
            sql = sql[start_pos:]
        
        sql = sql.split(';')[0]
        
        #  FIX: Safer auto-correction - removed risky global replace
        #  The prompt rules should handle 'blacklisted' -> 'whether_truck_blacklisted' mapping.
        #  Global regex replacement here risks changing string literals (e.g. WHERE status = 'blacklisted')
        #  if re.search(r'\b(vtm\.|FROM\s+\w+\s+AS\s+vtm).*\bblacklisted\b', sql, re.IGNORECASE):
        #      sql = re.sub(r'\bblacklisted\b', 'whether_truck_blacklisted', sql)
        
        return sql.strip().rstrip(';')

    def _get_focused_schema(self, tables: List[str]) -> str:
        """Get schema for relevant tables"""
        schema_docs = getattr(self.training_data_module, 'SCHEMA_DESCRIPTIONS', {})
        schema_parts = []
        
        for table in tables:
            if table in schema_docs:
                info = schema_docs[table]
                schema_parts.append(f"Table: {table} -- {info.get('description', '')}")
                for col, desc in info.get('columns', {}).items():
                    schema_parts.append(f"  - {col}: {desc}")
                schema_parts.append("")
        
        return "\n".join(schema_parts)

    def get_performance_report(self) -> str:
        """Generate performance report"""
        report = ["\n" + "="*80, "MODEL PERFORMANCE", "="*80]
        
        for model, stats in self.model_stats.items():
            if stats['attempts'] == 0:
                continue
            
            success_rate = (stats['successes'] / stats['attempts'] * 100)
            report.append(f"\nModel: {model}")
            report.append(f"  Attempts: {stats['attempts']}")
            report.append(f"  Successes: {stats['successes']} ({success_rate:.1f}%)")
            report.append(f"  Failures: {stats['failures']}")
            report.append(f"  Avg Time: {stats['avg_time']:.2f}s")
        
        report.append("="*80)
        return '\n'.join(report)


class ProductionSQLGenerator:
    """Production SQL generator with proper error handling"""
    
    def __init__(self, training_data_module):
        from sql_validator import EnhancedSQLValidator
        from rag_system import EnhancedSQLRAGSystem
        
        self.validator = EnhancedSQLValidator(training_data_module.SQL_RULES)
        self.training_data_module = training_data_module
        self.rag_system = EnhancedSQLRAGSystem(training_data_module, self.validator)
        
        self.llm_generator = AdaptiveLLMGenerator(
            self.rag_system, 
            self.validator, 
            self.training_data_module,
            max_retries=3
        )
        
        self.stats = {
            'cache_hits': 0,
            'llm_generations': 0,
            'total_queries': 0,
            'failures': 0,
            'total_time': 0
        }
        
        logging.info("="*80)
        logging.info("PRODUCTION SQL GENERATOR INITIALIZED")
        logging.info("="*80)
    
    def generate_sql(self, user_question: str, model_name: Optional[str] = None, 
                    use_cache: bool = True) -> Dict:
        """
         CORRECTED: Main generation pipeline with proper flow
        """
        self.stats['total_queries'] += 1
        start_time = time.time()
        
        logging.info(f"\n{'='*80}")
        logging.info(f"Query #{self.stats['total_queries']}: {user_question}")
        logging.info(f"{'='*80}")
        
        try:
            sql_query = None
            source = "Unknown"
            
            #  FIX: Better schema vs data query detection
            schema_query, table_name = self._handle_schema_query(user_question)
            if schema_query:
                logging.info(f"   Schema query detected for: {table_name}")
                sql_query = schema_query
                source = "deterministic_schema"
            
            # Check cache
            if use_cache and not sql_query:
                logging.info("1. Checking cache...")
                cached_sql = self.rag_system.find_in_cache(user_question)
                if cached_sql:
                    #  FIX: Validate cache and regenerate if invalid
                    is_valid, error = self.validator.validate_sql(cached_sql)
                    if is_valid:
                        sql_query = cached_sql
                        source = "cache_hit"
                        self.stats['cache_hits'] += 1
                        logging.info("   Cache hit")
                    else:
                        logging.warning(f"  ✗ Invalid cache entry: {error}")
                        self.rag_system.invalidate_cache_entry(user_question)
                        # Continue to LLM generation
            
            # LLM generation
            if not sql_query:
                logging.info("2. Attempting LLM generation...")
                sql_query, success, model_used = self.llm_generator.generate(
                    user_question,
                    use_few_shot=True,
                    model_name=model_name
                )
                
                if success:
                    source = f"{model_used}"
                    self.stats['llm_generations'] += 1
                else:
                    self.stats['failures'] += 1
            
            # Execute and validate
            if sql_query and "error" not in sql_query.lower():
                logging.info("3. Executing query...")
                execution_result = self.execute_query(sql_query)
                
                #  FIX: Improved sanity checks
                is_sane, feedback = self._perform_sanity_checks(
                    user_question, 
                    sql_query, 
                    execution_result, 
                    source
                )
                
                if execution_result.get("success") and is_sane:
                    # Cache successful query
                    if "deterministic" not in source:
                        self.rag_system.cache_successful_query(user_question, sql_query, source)
                    
                    answer = f"Query executed successfully. Found {execution_result.get('count', 0)} results."
                else:
                    # Attempt regeneration with feedback
                    if not is_sane:
                        logging.warning(f"  ✗ Sanity check failed: {feedback}")
                        logging.info("  Attempting regeneration...")
                        
                        sql_query, success, model_used = self.llm_generator.generate(
                            user_question,
                            use_few_shot=False,
                            force_error=feedback,
                            last_sql=sql_query,
                            model_name=model_name
                        )
                        
                        if success:
                            execution_result = self.execute_query(sql_query)
                            answer = f"Query executed after correction. Found {execution_result.get('count', 0)} results."
                        else:
                            answer = "Failed to generate correct query after multiple attempts."
                    else:
                        answer = f"Query execution failed: {execution_result.get('error', 'Unknown error')}"
            else:
                answer = "Failed to generate valid SQL query."
                execution_result = {"data": None}
            
            elapsed = time.time() - start_time
            self.stats['total_time'] += elapsed
            
            return {
                "answer": answer,
                "sql_query": sql_query,
                "data": execution_result.get("rows"),
                "source": source,
                "processing_time": f"{elapsed:.2f}s"
            }
        
        except Exception as e:
            self.stats['failures'] += 1
            logging.error(f"Fatal error: {e}")
            import traceback
            logging.error(traceback.format_exc())
            return {
                "answer": f"Critical error: {e}",
                "sql_query": None,
                "data": None,
                "source": "error"
            }
    
    def _handle_schema_query(self, question: str) -> Tuple[Optional[str], Optional[str]]:
        """
         FIX: Better schema vs data query detection. Handles multiple tables.
        """
        q_lower = question.lower().strip()
        
        schema_keywords = ['columns in', 'schema for', 'describe table', 'structure of', 'columns of']
        data_keywords = ['show me the', 'display the', 'list the', 'get the', 'find the', 'fetch the', 'values in']
        
        has_schema_keyword = any(kw in q_lower for kw in schema_keywords)
        is_data_query = any(kw in q_lower for kw in data_keywords)

        # If it's not a schema question, or if it's an ambiguous data question, exit.
        if not has_schema_keyword or is_data_query:
            return None, None

        # FIX: Robust table detection using synonyms/patterns
        found_tables = set()
        
        # 1. Exact match
        for tbl in self.validator.allowed_tables:
            if re.search(r'\b' + re.escape(tbl) + r'\b', q_lower):
                found_tables.add(tbl)
        
        # 2. Pattern match from training data
        table_patterns = self.training_data_module.SQL_RULES.get('table_patterns', {})
        for tbl, patterns in table_patterns.items():
            if tbl in self.validator.allowed_tables:
                for pattern in patterns:
                    if pattern.lower() in q_lower:
                        found_tables.add(tbl)
                        break

        if not found_tables:
            return None, None

        table_names = list(found_tables)

        # Build a query for each found table
        queries = []
        for table_name in table_names:
            queries.append(
                f"SELECT '{table_name}' as table_name, column_name, data_type, is_nullable, ordinal_position FROM information_schema.columns WHERE table_name = '{table_name}'"
            )
        
        # Combine with UNION ALL and order
        final_sql = " UNION ALL ".join(queries) + " ORDER BY table_name, ordinal_position;"
        
        logging.info(f"   Schema query detected for: {', '.join(table_names)}")
        return final_sql, ", ".join(table_names)
    
    def _perform_sanity_checks(self, question: str, sql: str, 
                               execution_result: Dict, source: str) -> Tuple[bool, str]:
        """
         CORRECTED: Improved sanity checks with better logic
        """
        if source == "deterministic_schema":
            return True, ""
        
        if not execution_result.get("success"):
            return True, ""  # Let execution error handle it
        
        rows = execution_result.get("rows", [])
        row_count = len(rows)
        q_lower = question.lower()
        sql_lower = sql.lower()
        
        #  FIX: Smarter row count check
        max_rows = 20000
        if row_count > max_rows:
            # Allow if it's an aggregation
            if "count(" in sql_lower or "group by" in sql_lower:
                return True, ""
            
            # Allow if user asked for "all"
            if "all" in q_lower or "every" in q_lower:
                return True, ""
            
            return False, f"Row count anomaly: {row_count} rows suggests bad JOIN. Add proper JOIN conditions or LIMIT clause."
        
        # Check for required information
        columns = [col.lower() for col in execution_result.get("columns", [])]
        
        required_concepts = {
            "risk score": ["risk_score"],
            "transporter": ["transporter_name", "transporter_code"]
        }
        
        for concept, related_cols in required_concepts.items():
            if "*" in sql:
                continue
            
            if concept in q_lower:
                if not any(col in columns for col in related_cols):
                    # Check if used in logic (GROUP BY, WHERE)
                    col_in_logic = any(col in sql_lower for col in related_cols)
                    is_agg = "group by" in sql_lower
                    
                    if not (is_agg and col_in_logic):
                        return False, f"Missing '{concept}' in output. Must select one of: {related_cols}"
        
        return True, ""
    
    def execute_query(self, sql: str) -> Dict:
        """Execute SQL query"""
        try:
            with self.validator.engine.connect() as conn:
                result = conn.execute(text(sql))
                rows = result.fetchall()
                columns = result.keys()
                return {
                    "success": True,
                    "columns": list(columns),
                    "rows": [dict(zip(columns, row)) for row in rows],
                    "count": len(rows)
                }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def print_stats(self):
        """Print statistics"""
        total = self.stats['total_queries']
        if total == 0:
            return
        
        success = total - self.stats['failures']
        
        print(f"\n{'='*80}")
        print("PERFORMANCE STATISTICS")
        print(f"{'='*80}")
        print(f"Total queries: {total}")
        print(f"Successful: {success} ({100*success/total:.1f}%)")
        print(f"Cache hits: {self.stats['cache_hits']} ({100*self.stats['cache_hits']/total:.1f}%)")
        print(f"LLM generated: {self.stats['llm_generations']} ({100*self.stats['llm_generations']/total:.1f}%)")
        print(f"Failures: {self.stats['failures']} ({100*self.stats['failures']/total:.1f}%)")
        print(f"Avg time: {self.stats['total_time']/total:.2f}s")
        print(f"{'='*80}\n")
        
        print(self.llm_generator.get_performance_report())